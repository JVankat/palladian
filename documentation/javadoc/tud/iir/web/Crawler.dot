#!/usr/local/bin/dot
#
# Class diagram 
# Generated by UMLGraph version 5.2 (http://www.umlgraph.org/)
#

digraph G {
	edge [fontname="arial",fontsize=10,labelfontname="arial",labelfontsize=10];
	node [fontname="arial",fontsize=10,shape=plaintext];
	nodesep=0.25;
	ranksep=0.5;
	// tud.iir.web.Crawler
	c57030 [label=<<table title="tud.iir.web.Crawler" border="0" cellborder="1" cellspacing="0" cellpadding="2" port="p" bgcolor="lemonChiffon" href="./Crawler.html">
		<tr><td><table border="0" cellspacing="0" cellpadding="1">
<tr><td align="center" balign="center"> Crawler </td></tr>
		</table></td></tr>
		<tr><td><table border="0" cellspacing="0" cellpadding="1">
<tr><td align="left" balign="left"> - logger : Logger </td></tr>
<tr><td align="left" balign="left"> - config : PropertiesConfiguration </td></tr>
<tr><td align="left" balign="left"> - USER_AGENT : String </td></tr>
<tr><td align="left" balign="left"> - REFERER : String </td></tr>
<tr><td align="left" balign="left"> - CONNECTION_TIMEOUT : int </td></tr>
<tr><td align="left" balign="left"> - READ_TIMEOUT : int </td></tr>
<tr><td align="left" balign="left"> + BYTES : int </td></tr>
<tr><td align="left" balign="left"> + KILO_BYTES : int </td></tr>
<tr><td align="left" balign="left"> + MEGA_BYTES : int </td></tr>
<tr><td align="left" balign="left"> + GIGA_BYTES : int </td></tr>
<tr><td align="left" balign="left"> + sessionDownloadedBytes : long </td></tr>
<tr><td align="left" balign="left"> - maxThreads : int </td></tr>
<tr><td align="left" balign="left"> - threadCount : int </td></tr>
<tr><td align="left" balign="left"> - stopCount : int </td></tr>
<tr><td align="left" balign="left"> - urlStack : HashSet&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> - visitedURLs : HashSet&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> - seenURLs : HashSet&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> - onlyFollow : HashSet&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> - urlRules : HashSet&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> - urlDump : HashSet&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> - parser : DOMParser </td></tr>
<tr><td align="left" balign="left"> - document : Document </td></tr>
<tr><td align="left" balign="left"> - totalDownloadSize : int </td></tr>
<tr><td align="left" balign="left"> - lastDownloadSize : int </td></tr>
<tr><td align="left" balign="left"> - inDomain : boolean </td></tr>
<tr><td align="left" balign="left"> - outDomain : boolean </td></tr>
<tr><td align="left" balign="left"> - crawlerCallback : CrawlerCallback </td></tr>
<tr><td align="left" balign="left"> - proxy : Proxy </td></tr>
<tr><td align="left" balign="left"> - switchProxyRequests : int </td></tr>
<tr><td align="left" balign="left"> - proxyList : List&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> - proxyIndex : int </td></tr>
<tr><td align="left" balign="left"> - requestsSent : int </td></tr>
		</table></td></tr>
		<tr><td><table border="0" cellspacing="0" cellpadding="1">
<tr><td align="left" balign="left"> - initialize(configPath : String) </td></tr>
<tr><td align="left" balign="left"> + loadConfig(configPath : String) </td></tr>
<tr><td align="left" balign="left"> + startCrawl(urlStack : HashSet&lt;String&gt;, inDomain : boolean, outDomain : boolean) </td></tr>
<tr><td align="left" balign="left"> + startCrawl(startURL : String, inDomain : boolean, outDomain : boolean) </td></tr>
<tr><td align="left" balign="left"> - startCrawl() </td></tr>
<tr><td align="left" balign="left"> - getURLFromStack() : String </td></tr>
<tr><td align="left" balign="left"> - removeURLFromStack(url : String) </td></tr>
<tr><td align="left" balign="left"> + setStopCount(number : int) </td></tr>
<tr><td align="left" balign="left"> + addOnlyFollow(follow : String) </td></tr>
<tr><td align="left" balign="left"> + addURLRule(rule : String) </td></tr>
<tr><td align="left" balign="left"> - addURLsToStack(urls : HashSet&lt;String&gt;, sourceURL : String) </td></tr>
<tr><td align="left" balign="left"> - addURLToStack(url : String, sourceURL : String) </td></tr>
<tr><td align="left" balign="left"> - checkURLRules(url : String) : boolean </td></tr>
<tr><td align="left" balign="left"> # crawl(currentURL : String) </td></tr>
<tr><td align="left" balign="left"> + saveURLDump(filename : String) </td></tr>
<tr><td align="left" balign="left"> + getLinks(inDomain : boolean, outDomain : boolean) : HashSet&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> + getLinks(inDomain : boolean, outDomain : boolean, prefix : String) : HashSet&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> + getLinks(document : Document, inDomain : boolean, outDomain : boolean) : HashSet&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> + getLinks(document : Document, inDomain : boolean, outDomain : boolean, prefix : String) : HashSet&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> + getDomain(url : String, includeProtocol : boolean) : String </td></tr>
<tr><td align="left" balign="left"> + extractTitle(webPage : Document) : String </td></tr>
<tr><td align="left" balign="left"> + extractBodyContent(webPage : Document) : String </td></tr>
<tr><td align="left" balign="left"> + extractKeywords(webPage : Document) : ArrayList&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> + extractDescription(webPage : Document) : ArrayList&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> + urlDecode(url : String) : String </td></tr>
<tr><td align="left" balign="left"> + makeFullURL(url : String, link : String) : String </td></tr>
<tr><td align="left" balign="left"> + getSiblingPage(url : String) : String </td></tr>
<tr><td align="left" balign="left"> + getSiblingPage(document : Document) : String </td></tr>
<tr><td align="left" balign="left"> + getCleanURL(url : String) : String </td></tr>
<tr><td align="left" balign="left"> + removeAnchors(url : String) : String </td></tr>
<tr><td align="left" balign="left"> - getUserAgent() : String </td></tr>
<tr><td align="left" balign="left"> + getXMLDocument(url : String) : Document </td></tr>
<tr><td align="left" balign="left"> + setDocument(document : Document) </td></tr>
<tr><td align="left" balign="left"> + setDocument(url : String) </td></tr>
<tr><td align="left" balign="left"> + setDocument(url : String, isFile : boolean) </td></tr>
<tr><td align="left" balign="left"> + getDocument() : Document </td></tr>
<tr><td align="left" balign="left"> + getDocument(url : String) : Document </td></tr>
<tr><td align="left" balign="left"> + getDocument(url : String, isFile : boolean) : Document </td></tr>
<tr><td align="left" balign="left"> + getJSON(url : String) : JSONObject </td></tr>
<tr><td align="left" balign="left"> + download(urlString : String, stripTags : boolean, stripComments : boolean, stripJSAndCSS : boolean, joinTagsAndRemoveNewlines : boolean) : String </td></tr>
<tr><td align="left" balign="left"> + download(urlString : String) : String </td></tr>
<tr><td align="left" balign="left"> + download(urlString : String, stripTags : boolean) : String </td></tr>
<tr><td align="left" balign="left"> + downloadAndSave(urlSet : HashSet&lt;String&gt;) </td></tr>
<tr><td align="left" balign="left"> + downloadAndSave(file : File) </td></tr>
<tr><td align="left" balign="left"> + downloadAndSave(file : File, startLine : int) </td></tr>
<tr><td align="left" balign="left"> + downloadAndSave(urlString : String, path : String) : boolean </td></tr>
<tr><td align="left" balign="left"> + downloadImage(url : String, path : String) </td></tr>
<tr><td align="left" balign="left"> + getTotalDownloadSize() : double </td></tr>
<tr><td align="left" balign="left"> + getTotalDownloadSize(unit : int) : double </td></tr>
<tr><td align="left" balign="left"> + setTotalDownloadSize(totalDownloadSize : int) </td></tr>
<tr><td align="left" balign="left"> + getLastDownloadSize() : int </td></tr>
<tr><td align="left" balign="left"> + setLastDownloadSize(lastDownloadSize : int) </td></tr>
<tr><td align="left" balign="left"> - addDownloadSize(size : int) </td></tr>
<tr><td align="left" balign="left"> - callCrawlerCallback(document : Document) </td></tr>
<tr><td align="left" balign="left"> + getCrawlerCallback() : CrawlerCallback </td></tr>
<tr><td align="left" balign="left"> + setCrawlerCallback(crawlerCallback : CrawlerCallback) </td></tr>
<tr><td align="left" balign="left"> + getMaxThreads() : int </td></tr>
<tr><td align="left" balign="left"> + setMaxThreads(maxThreads : int) </td></tr>
<tr><td align="left" balign="left"> + getThreadCount() : int </td></tr>
<tr><td align="left" balign="left"> + increaseThreadCount() </td></tr>
<tr><td align="left" balign="left"> + decreaseThreadCount() </td></tr>
<tr><td align="left" balign="left"> + getProxy() : Proxy </td></tr>
<tr><td align="left" balign="left"> + setProxy(proxy : Proxy) </td></tr>
<tr><td align="left" balign="left"> - checkChangeProxy() </td></tr>
<tr><td align="left" balign="left"> + setSwitchProxyRequests(switchProxyRequests : int) </td></tr>
<tr><td align="left" balign="left"> + getSwitchProxyRequests() : int </td></tr>
<tr><td align="left" balign="left"> + setProxyList(proxyList : List&lt;String&gt;) </td></tr>
<tr><td align="left" balign="left"> + getProxyList() : List&lt;String&gt; </td></tr>
<tr><td align="left" balign="left"> + changeProxy() </td></tr>
<tr><td align="left" balign="left"> + checkProxy() : boolean </td></tr>
<tr><td align="left" balign="left"> + getHeaders(pageURL : String) : Map&lt;String, List&lt;String&gt;&gt; </td></tr>
<tr><td align="left" balign="left"> + isValidURL(pageURL : String) : boolean </td></tr>
<tr><td align="left" balign="left"> + main(args : String[]) </td></tr>
		</table></td></tr>
		</table>>, fontname="arial", fontcolor="black", fontsize=10.0];
}

